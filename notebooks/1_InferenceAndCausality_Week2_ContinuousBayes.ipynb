{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guess the Coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4123ad755193404eb44fdf970fc68896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='Heads', max=10), IntSlider(value=5, description='Tosses'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Week 2 — From Discrete to Continuous Bayes\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "from ipywidgets import interact, IntSlider\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "# --- Parameters ---\n",
    "# prior parameters (Beta distribution)\n",
    "a_prior, b_prior = 2, 2   # \"probably fair\" — centered around 0.5\n",
    "\n",
    "# --- Helper function ---\n",
    "def plot_posterior(heads=0, tosses=0):\n",
    "    \"\"\"\n",
    "    Plot prior, likelihood (up to scale), and posterior for given data.\n",
    "    heads: number of observed heads\n",
    "    tosses: total number of coin tosses\n",
    "    \"\"\"\n",
    "    x = np.linspace(0, 1, 400)\n",
    "    \n",
    "    # prior Beta(a,b)\n",
    "    prior = beta.pdf(x, a_prior, b_prior)\n",
    "    \n",
    "    # posterior Beta(a+a_prior, b+b_prior)\n",
    "    a_post = a_prior + heads\n",
    "    b_post = b_prior + tosses - heads\n",
    "    posterior = beta.pdf(x, a_post, b_post)\n",
    "    \n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(x, prior, \"--\", label=f\"Prior Beta({a_prior},{b_prior})\")\n",
    "    plt.plot(x, posterior, label=f\"Posterior Beta({a_post},{b_post})\")\n",
    "    plt.fill_between(x, posterior, alpha=0.2)\n",
    "    plt.xlabel(\"Coin bias θ (probability of heads)\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(f\"{heads} heads out of {tosses} tosses\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# --- Interactive widget ---\n",
    "interact(plot_posterior,\n",
    "         heads=IntSlider(min=0, max=10, step=1, value=4, description=\"Heads\"),\n",
    "         tosses=IntSlider(min=1, max=10, step=1, value=5, description=\"Tosses\"));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Exercise\n",
    "Play with the sliders until you find a situation where your prior and data disagree.\n",
    "- Describe what happens to the posterior.\n",
    "- Why doesn’t it completely ignore your prior after only a few tosses?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. As the prior mean is already fixed, only the data can be varied here. And when the observed data strongly disagrees with the prior belief, the posterior distribution shifts to a compromise value which lies between the prior mean(0.5) and the data's observed frequency(1.0). Then the posterior curve becomes much taller and narrower than the prior curve because the addition of real data significantly increases certainity by reducing variance. The posterior mean doesn't reach the observed frequency(1.0) because the weak but existing prior evidence still pulls the estimate slightly back toward 0.5.\n",
    "\n",
    "2. The posterior distribution doesn't completely ignore the prior, even after a few contradictory tosses, because the Beta prior acts mathematically as \"pseudo-data\" that must be outweighed by the actual evidence. Since the default Beta(2,2) is equivalent to having seen 4 prior observations (2 heads and 2 tails), if we only input a few new tosses, our total evidence is still small. The strength of the new likelihood is insufficient to completely override the initial 4 pseudo-observations, forcing the resulting posterior to remain weighted average that incorporates the prior belief."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
